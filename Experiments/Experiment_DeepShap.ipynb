{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "T4",
   "mount_file_id": "1TCv6Uu6Fd7sJ2gKbkOuu5VgcQ1zIDCa_",
   "authorship_tag": "ABX9TyP4DuLcwsGJaI74HyQ8sRTm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Experiments and Evaluation of Shap\n",
    "- Evaluation protocol for Deep Shap following evaluation procedure and skill score calculation described in **[\"Finding the right XAI Method --- A Guide for the Evaluation and Ranking of Explainable AI Methods in Climate Science](https://arxiv.org/abs/2303.00652)**  by Bommer et. al.\n",
    "- **Note that** the calculations have been seperated into a Colab python notebook due to version conflicts with innvestigate v.1.0.9\n",
    "- For execution via Colab:\n",
    "    - 1.) create colab account\n",
    "    - 2.) sync to colab drive (use colab app) and create shortcut in google drive (right click -> organise -> shortcut)\n",
    "    - 3.) adapt paths in 'Preliminaries'"
   ],
   "metadata": {
    "id": "e2fCHKLcEIjV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Install packages.\n",
    "!pip install scipy==1.10.1\n",
    "!pip install matplotlib==3.5.3\n",
    "!pip install keras\n",
    "!pip install shap"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "id": "tz-f9_vrIFwN",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689186018616,
     "user_tz": -120,
     "elapsed": 19844,
     "user": {
      "displayName": "Philine Lou",
      "userId": "11745850249216413368"
     }
    },
    "outputId": "cbd23e2c-7a43-4cbd-c9e6-d6fab193cd99"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy==1.10.1) (1.22.4)\n",
      "Collecting matplotlib==3.5.3\n",
      "  Downloading matplotlib-3.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.9/11.9 MB\u001B[0m \u001B[31m87.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.3) (1.16.0)\n",
      "Installing collected packages: matplotlib\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.7.1\n",
      "    Uninstalling matplotlib-3.7.1:\n",
      "      Successfully uninstalled matplotlib-3.7.1\n",
      "Successfully installed matplotlib-3.5.3\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "matplotlib",
         "mpl_toolkits"
        ]
       }
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
      "Collecting shap\n",
      "  Downloading shap-0.42.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (547 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m547.1/547.1 kB\u001B[0m \u001B[31m40.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.22.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.65.0)\n",
      "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.1)\n",
      "Collecting slicer==0.0.7 (from shap)\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.56.4)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->shap) (67.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2022.7.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
      "Installing collected packages: slicer, shap\n",
      "Successfully installed shap-0.42.0 slicer-0.0.7\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3eTBrYdCHzK4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689186104430,
     "user_tz": -120,
     "elapsed": 85826,
     "user": {
      "displayName": "Philine Lou",
      "userId": "11745850249216413368"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "919e3438-5b68-42c8-ec42-52b18c210e2c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "# Import python packages.\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import json\n",
    "import os\n",
    "# Mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "# Install a local package.\n",
    "!pip install -e /content/drive/MyDrive/Climate_X_Quantus/QuantusClimate/. --user"
   ],
   "metadata": {
    "id": "HEvAcWvW7rau"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "!pip freeze"
   ],
   "metadata": {
    "id": "7hFKWMafaF-f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "# Import local package.\n",
    "import sys\n",
    "sys.path.insert(0,'/content/drive/My Drive/Climate_X_Quantus/')\n",
    "import QuantusClimate as quantus"
   ],
   "metadata": {
    "id": "YK52JG5goMhF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions"
   ],
   "metadata": {
    "id": "tAX_zLBa_RSy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "from typing import Dict, Any, Tuple\n",
    "\n",
    "def generate_tf_innvestigation(\n",
    "    model, inputs, targets, **kwargs\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate explanation for a tf model with innvestigate and NoiseGrad and FusionGrad\n",
    "    tensorflow implementation\n",
    "    :param model: trained model instance keras.model\n",
    "    :param inputs: input sample\n",
    "    :param targets: vectore of according true class labels\n",
    "    :param kwargs: 'num_classes' - number of classes\n",
    "                   'nr_samples' - number of iterations of the evaluation metric\n",
    "                   'explanation' - true explanation\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    method = kwargs.get(\"method\", \"random\")\n",
    "    og_shape = inputs.shape\n",
    "\n",
    "    inputs = inputs.reshape(-1, *model.input_shape[1:])\n",
    "\n",
    "    explanation = np.zeros_like(inputs)\n",
    "\n",
    "    if not method:\n",
    "        raise KeyError(\n",
    "            \"Specify a XAI method that already has been implemented.\"\n",
    "        )\n",
    "\n",
    "    elif \"DeepSHAP\" in method[2]:\n",
    "\n",
    "        base = method[1][\"base\"]\n",
    "        if 'MLP' in method[1][\"net\"]:\n",
    "          base = base.reshape((len(base),method[1][\"lat\"]*method[1][\"lon\"]))\n",
    "          inputs = inputs.reshape((len(inputs),method[1][\"lat\"]*method[1][\"lon\"]))\n",
    "        else:\n",
    "          base = base.reshape((len(base),method[1][\"lat\"],method[1][\"lon\"],1))\n",
    "          inputs = inputs.reshape((len(inputs),method[1][\"lat\"],method[1][\"lon\"],1))\n",
    "\n",
    "        exp = shap.DeepExplainer(model, base)\n",
    "\n",
    "        if kwargs.get('num_classes', 0) > 0:\n",
    "            expl = []\n",
    "            s_values = exp.shap_values(inputs, check_additivity=False)\n",
    "\n",
    "\n",
    "            for itrs in range(0, targets.shape[0]):\n",
    "                if targets[itrs] == 0:\n",
    "                    pred = np.argmax(model.predict(inputs[np.newaxis, itrs, ...]))\n",
    "                    idx = np.random.choice(\n",
    "                        [y_ for y_ in list(np.arange(0, kwargs.get('num_classes', 0))) if y_ != pred]\n",
    "                    )\n",
    "\n",
    "                    expl.append(np.array(s_values[idx][itrs,...]))\n",
    "                else:\n",
    "                    expl.append(np.array(s_values[targets[itrs]][itrs,...]))\n",
    "            explanation = np.array(expl).reshape(inputs.shape)\n",
    "        else:\n",
    "            s_values = exp.shap_values(inputs,  ranked_outputs=1, check_additivity=False)\n",
    "\n",
    "            shap_values, indexes = exp.shap_values(inputs,  ranked_outputs=1, check_additivity=False)\n",
    "            explanation = np.array(shap_values[0])\n",
    "\n",
    "    if np.isnan(explanation).sum()>0:\n",
    "        print(\"<<< Error: All explanations are nans >>>\")\n",
    "\n",
    "    return explanation.reshape(og_shape)\n"
   ],
   "metadata": {
    "id": "uIBs8gW3_V_y"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "\n",
    "def run_quantus(args: Dict,\n",
    "                explanations: Dict,\n",
    "                metrics: Dict,\n",
    "                xai_methods: Any,\n",
    "                **params,\n",
    "                ):\n",
    "    \"\"\"\n",
    "    Function running pre-defined evaluation metrics in quantus on different explanation techniques\n",
    "    :param args: model - keras.Model (trained model instance)\n",
    "                x_batch - input batch\n",
    "                y_batch - output batch\n",
    "                s_batch - explanation batch\n",
    "                n_samp - number of iterations for evaluation procedure\n",
    "                num_cl -  number of classes\n",
    "    :param explanations: same as s_batch\n",
    "    :param metrics: Dict of metric function and hyperparameter settings\n",
    "    :param xai_methods: dict of explanation name and hyperparameters settings\n",
    "    :param params: dirout - output directory for back-up files in\n",
    "                   csvfile - filename for back-up\n",
    "    :return: dict of {metric: explanation: scores (float or array)}\n",
    "    \"\"\"\n",
    "\n",
    "    results = {metric: {} for metric, metric_func in metrics.items()}\n",
    "    dirout = params['dirout']\n",
    "    csv_file = params['csvfile']\n",
    "    for metric, metric_func in metrics.items():\n",
    "        if metric is \"RandomLogit\":\n",
    "            num_cl = args[\"num_cl\"]\n",
    "        else:\n",
    "            num_cl = 0\n",
    "\n",
    "\n",
    "        for method in xai_methods:\n",
    "            print(metric, \":\", method[2])\n",
    "            if metric == \"ROAD\":\n",
    "                scores = []\n",
    "                for i in range(args[\"n_iter\"]):\n",
    "                    score = metric_func(model=args['model'],\n",
    "                                         x_batch=args['x_batch'],\n",
    "                                         y_batch=args['y_batch'],\n",
    "                                         a_batch=explanations[method[2]],\n",
    "                                         s_batch=args['s_batch'],\n",
    "                                         explain_func=generate_tf_innvestigation,\n",
    "                                         explain_func_kwargs={\"method\": method,\n",
    "                                                              \"explanation\": explanations[method[2]],\n",
    "                                                              'nr_samples':  args[\"n_smps\"],\n",
    "                                                              \"num_classes\": num_cl})\n",
    "                    scores.append(score)\n",
    "            elif metric in [\"Robustness\", \"LocalLipschitzEstimate\", \"AvgSensitivity\"]:\n",
    "                scores = []\n",
    "                if method[0] == \"Control Var. Random Uniform\":\n",
    "                    as_list = list(method)\n",
    "                    as_list[1] = {'fix': 0}\n",
    "                    method = tuple(as_list)\n",
    "                if params['net'] == 'CNN':\n",
    "                    for i in range(args[\"n_iter\"]):\n",
    "                        score = metric_func(model=args['model'],\n",
    "                                             x_batch=args['x_batch'][i*args[\"n_sms\"]:(i+1)*args[\"n_sms\"],...],\n",
    "                                             y_batch=args['y_batch'][i*args[\"n_sms\"]:(i+1)*args[\"n_sms\"]],\n",
    "                                             a_batch=explanations[method[2]][i*args[\"n_sms\"]:(i+1)*args[\"n_sms\"],...],\n",
    "                                             s_batch=args['s_batch'][i*args[\"n_sms\"]:(i+1)*args[\"n_sms\"],...],\n",
    "                                             explain_func=generate_tf_innvestigation,\n",
    "                                             explain_func_kwargs={\"method\": method,\n",
    "                                                                  \"explanation\": explanations[method[2]][i*args[\"n_sms\"]:(i+1)*args[\"n_sms\"],...],\n",
    "                                                                  'nr_samples': args[\"n_sms\"],\n",
    "                                                                  \"num_classes\": num_cl})\n",
    "                        scores.append(score)\n",
    "                else:\n",
    "                    scores = metric_func(model=args['model'],\n",
    "                                         x_batch=args['x_batch'],\n",
    "                                         y_batch=args['y_batch'],\n",
    "                                         a_batch=explanations[method[2]],\n",
    "                                         s_batch=args['s_batch'],\n",
    "                                         explain_func=generate_tf_innvestigation,\n",
    "                                         explain_func_kwargs={\"method\": method,\n",
    "                                                              \"explanation\": explanations[method[2]],\n",
    "                                                              'nr_samples': args[\"n_smps\"],\n",
    "                                                              \"num_classes\": num_cl})\n",
    "            else:\n",
    "                scores = metric_func(model=args['model'],\n",
    "                            x_batch=args['x_batch'],\n",
    "                            y_batch=args['y_batch'],\n",
    "                            a_batch=explanations[method[2]],\n",
    "                            s_batch=args['s_batch'],\n",
    "                            explain_func=generate_tf_innvestigation,\n",
    "                            explain_func_kwargs={\"method\": method,\n",
    "                                                 \"explanation\": explanations[method[2]],\n",
    "                                                 'nr_samples': args[\"n_smps\"],\n",
    "                                                 \"num_classes\": num_cl})\n",
    "\n",
    "            results[metric][method[2]] = scores\n",
    "\n",
    "    return results\n"
   ],
   "metadata": {
    "id": "WOglcVXa_3Cg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "import sklearn.metrics as metrix\n",
    "\n",
    "def area_score(results: Any,\n",
    "                     ** kwargs):\n",
    "    \"\"\"\n",
    "    Implements an area under the curve metric for ROAD graph\n",
    "    \"\"\"\n",
    "    y = np.zeros((len(results.values()),))\n",
    "    x = np.zeros((len(results.values()),))\n",
    "    i = 0\n",
    "    for keys, vals in results.items():\n",
    "\n",
    "        y[i] = vals\n",
    "        x[i] = float(keys)\n",
    "\n",
    "        i+=1\n",
    "    score =  metrix.auc(x,y)\n",
    "    return score\n",
    "\n",
    "def bss_mean_var(metricx: Dict,\n",
    "                         methods: Dict,\n",
    "                         results: Dict,\n",
    "                         base: Dict,\n",
    "                         **params):\n",
    "    \"\"\"\n",
    "    Calculates breier skill score satistics including mean BSS and SEM across samples in scores[metric][method]\n",
    "    :param metrics: dict of quantus metrics\n",
    "    :param methods: dict of explanation methods\n",
    "    :param scores:  dict of scores for each metric and each XAI method\n",
    "    :param params:  kwargs with number of XAI methods and names of the properties (network comparison see defaults)\n",
    "                or metrics that underlie normalization according to Eq.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Set params.\n",
    "    num_xai = params.get('num_xai', 8)\n",
    "    string_list = params.get('min_norm', [\"Randomisation\", \"Robustness\"])\n",
    "\n",
    "    #Initialize result dicts.\n",
    "    means = {}\n",
    "    var = {}\n",
    "    i = 0\n",
    "    # Aggregate mean and SEM.\n",
    "    for metric, metric_func in metricx.items():\n",
    "        means[metric] = {}\n",
    "        var[metric] = {}\n",
    "        unnormed_scores = []\n",
    "        for j, methoddict in enumerate(methods):\n",
    "            method = methoddict[2]\n",
    "            if metric is \"ROAD\":\n",
    "                u_sc = []\n",
    "                for r in range(len(results[metric][method])):\n",
    "                    agg_score = area_score(results[metric][method][r])\n",
    "                    u_sc.append(agg_score)\n",
    "                unnormed_scores.append(np.array(u_sc))\n",
    "            elif type(results[metric][method]) is dict:\n",
    "                u_scores = []\n",
    "                for vals in results[metric][method].values():\n",
    "                    u_scores.append(vals)\n",
    "\n",
    "                unnormed_scores.append(np.array(u_scores).flatten())\n",
    "            else:\n",
    "                unnormed_scores.append(np.array(results[metric][method]).flatten())\n",
    "\n",
    "        unnormed_scores = np.array(unnormed_scores)\n",
    "\n",
    "        if metric is \"ROAD\":\n",
    "              b_sc = []\n",
    "              for r in range(len(base[metric])):\n",
    "                  agg_score = area_score(base[metric][r])\n",
    "                  b_sc.append(agg_score)\n",
    "              base_score = np.abs(np.array(b_sc)).reshape(unnormed_scores[0].shape)\n",
    "        elif type(base[metric]) is dict:\n",
    "                b_scores = []\n",
    "                for vals in base[metric].values():\n",
    "                    b_scores.append(vals)\n",
    "\n",
    "                base_score = np.array(b_scores).flatten().reshape(unnormed_scores[0].shape)\n",
    "        else:\n",
    "              base_score = base[metric].reshape(unnormed_scores[0].shape)\n",
    "        base_scores = np.repeat(base_score[np.newaxis, :], num_xai, axis=0)\n",
    "\n",
    "        if metric in string_list:\n",
    "            unnormed_scores = np.abs(unnormed_scores)\n",
    "            scores = np.ones(base_scores.shape) - (unnormed_scores/base_scores)\n",
    "        else:\n",
    "            scores = (unnormed_scores - base_scores)/(np.ones(base_scores.shape)-base_scores)\n",
    "\n",
    "        for i, methoddict in enumerate(methods):\n",
    "            meth = methoddict[2]\n",
    "            if np.isinf(np.abs(np.mean(scores[i, :]))):\n",
    "                means[metric][meth] = np.nanmean(np.ma.masked_invalid(scores[i, :]))\n",
    "            else:\n",
    "                means[metric][meth] = np.nanmean(scores[i, :])\n",
    "            if np.isinf(np.std(scores[i, :])):\n",
    "                var[metric][meth] = np.nanstd(np.ma.masked_invalid(scores[i, :]))/ np.sqrt(scores.shape[1])\n",
    "            else:\n",
    "                var[metric][meth] = np.nanstd(scores[i, :]) / np.sqrt(scores.shape[1])\n",
    "        i += 1\n",
    "    return means, var\n"
   ],
   "metadata": {
    "id": "awy-dF-NHPQv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preliminaries\n",
    "\n",
    "- Set raw_path to raw data path\n",
    "- Set save_path to DeepShap result path\n",
    "- Set score_path to general result path (holding data from python script evaluation)\n",
    "- Set net = 'MLP' for MLP-based evaluation of DeepShap\n",
    "- Set net = 'CNN' for CNN-based evaluation of DeepShap\n",
    "\n",
    "- Set properties = '#_0' with # = {Robustness, Faithfulness, Complexity}\n",
    "  - Robustness runs Robustness evaluation (incl. Lipschitz Estimate & Max. Sensitivity)\n",
    "  - Faithfulness runs Faithfulness evaluation (incl. Faithfulness Correlation & ROAD)\n",
    "  - Complexity runs Complexity, Localization and Randomization evaluation (incl. Complexity, Sparseness, Relevance Rank Accuracy, Top-k, Model Parameter Randomization Test and Random Logit Test)"
   ],
   "metadata": {
    "id": "kauWxgSSnyC2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Set experiment paths.\n",
    "import yaml\n",
    "\n",
    "exp_path = '/content/drive/MyDrive/Climate_X_Quantus/Experiment/'\n",
    "raw_path = '/content/drive/MyDrive/Climate_X_Quantus/Data/'\n",
    "save_path = '/content/drive/MyDrive/Climate_X_Quantus/Data/Quantus/Baseline/Shap/'\n",
    "score_path = '/content/drive/MyDrive/Climate_X_Quantus/Data/Quantus/Baseline/'\n",
    "\n",
    "if not os.path.isdir(score_path):\n",
    "    print(\"path does not exist\")\n",
    "    os.mkdir(score_path)\n",
    "    os.mkdir(save_path)"
   ],
   "metadata": {
    "id": "zIB21em4n66u"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set experiment settings.\n",
    "\n",
    "config = yaml.load(open(exp_path + 'plot_config.yaml'), Loader=yaml.FullLoader)\n",
    "post_settings = yaml.load(open(exp_path + 'Post_config.yaml'), Loader=yaml.FullLoader)\n",
    "\n",
    "# Experiment variables.\n",
    "properties = 'Complexity_0'\n",
    "net = 'CNN'\n",
    "params = config['params']\n",
    "params['net'] = net\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Data\n"
   ],
   "metadata": {
    "id": "btIuU89W6aAz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the full data object.\n",
    "all = np.load(raw_path + 'Quantus/%s' + '/0/' + 'Postprocessed_data_ALL.npz', allow_pickle=True)\n",
    "background= all[\"Input\"].reshape(all[\"Input\"].shape[0], 1, len(all[\"wh\"][0]), len(all[\"wh\"][1]))\n",
    "\n",
    "# select a set of background examples to take an expectation over.\n",
    "background = background[np.random.choice(background.shape[0], 100, replace=False)]\n",
    "\n",
    "# Longitude and latitudes.\n",
    "lat = all['wh'][0]\n",
    "lon = all['wh'][1]\n",
    "\n",
    "del all\n",
    "\n",
    "#Load experiment data, including random baseline samples`.\n",
    "data = np.load(raw_path + 'Quantus/Baseline/' + 'data_%s_%s.npz' % (properties, net), allow_pickle=True)\n",
    "\n",
    "# Input images.\n",
    "if 'MLP' in net:\n",
    "  x_batch = data['x_batch'].swapaxes(1,3).swapaxes(1,2)\n",
    "else:\n",
    "  x_batch = data['x_batch']#.swapaxes(1,3).swapaxes(1,2)\n",
    "\n",
    "\n",
    "# Classification labels.\n",
    "y_batch = data['y_batch']\n",
    "\n",
    "# mask data.\n",
    "s_batch = data['s_batch']#.swapaxes(1,3).swapaxes(1,2)\n",
    "\n",
    "# Years of the input images.\n",
    "y_out= data['y_out']\n",
    "\n",
    "# Experiment settings.\n",
    "n_smps=data['n_smps']\n",
    "n_sms= data['n_sms']\n",
    "n_iter= data['n_iter']\n",
    "num_cl= y_out.shape[1]\n",
    "\n",
    "# Reference scores.\n",
    "ref = data['reference']"
   ],
   "metadata": {
    "id": "-MdztJuA6YiG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load model\n",
    "- load trained model"
   ],
   "metadata": {
    "id": "eBz8AmkI_rIX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.models import load_model\n",
    "import keras\n",
    "\n",
    "model = load_model(raw_path + '/Network/' + 'lens_%s_0_T2M_1.tf' % net, compile=False)\n",
    "\n",
    "# Run the model on a test sample, requiring a compilation.\n",
    "model.compile(optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[keras.metrics.categorical_accuracy],)\n",
    "print(model)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Stq2LmFl6YyB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689186201038,
     "user_tz": -120,
     "elapsed": 4766,
     "user": {
      "displayName": "Philine Lou",
      "userId": "11745850249216413368"
     }
    },
    "outputId": "10e338c0-2d12-4d87-d651-0ecacce2a711"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<keras.engine.functional.Functional object at 0x7ad4d7f75c60>\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The `lr` argument is deprecated, use `learning_rate` instead.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create explanations SHAP\n",
    "- Generation of explanation such to pass to the evaluation metrics as samples"
   ],
   "metadata": {
    "id": "Rwn2s-NXBWpb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Reshape Data\n",
    "if 'MLP' in net:\n",
    "  backg = background.reshape((len(background),len(lat)*len(lon)))\n",
    "  x_b= x_batch.reshape((len(x_batch), len(lat)*len(lon)))\n",
    "\n",
    "else:\n",
    "  backg = background.reshape((len(background),len(lat),len(lon),1))\n",
    "  x_b = x_batch.reshape((len(x_batch), len(lat),len(lon),1))"
   ],
   "metadata": {
    "id": "cvxfbkNYKFiQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import shap\n",
    "\n",
    "# Explanation variables.\n",
    "xai_methods =[(\"DeepSHAP\", {\"base\": backg, \"lat\":len(lat),\"lon\":len(lon), \"net\":net}, \"DeepSHAP\")]\n",
    "explanations = {}\n",
    "\n",
    "# explain predictions of the model on three images\n",
    "exp = shap.DeepExplainer(model, backg)\n",
    "shapley_values = exp.shap_values(x_b, ranked_outputs=1,check_additivity=False)\n",
    "\n",
    "if 'MLP' in net:\n",
    "  explanations[xai_methods[0][0]] = shapley_values[0][0].reshape((len(x_batch), 1, len(lat),len(lon)))\n",
    "else:\n",
    "    explanations[xai_methods[0][0]] = shapley_values[0][0].reshape(x_batch.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CMHAZ39LAAZ-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689186215836,
     "user_tz": -120,
     "elapsed": 14810,
     "user": {
      "displayName": "Philine Lou",
      "userId": "11745850249216413368"
     }
    },
    "outputId": "d56433e3-88dd-4f82-e631-106f2a33333f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "keras is no longer supported, please use tf.keras instead.\n",
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x7ad4c06275b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x7ad4c06765f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Quantus Experiment"
   ],
   "metadata": {
    "id": "vENCXx_qz98j"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set up configuration\n",
    "- create metrics dict and set metrics hyperparameters for the evaluation metrics\n",
    "- build baseline (reference) dict from loaded previous experiment results (This guarantees that all skill scores are calculated based on the same skill score)"
   ],
   "metadata": {
    "id": "FgSvNMPxxOWV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "arguments = {'model': model,\n",
    "                'x_batch': x_batch,\n",
    "                'y_batch': y_batch,\n",
    "                's_batch': s_batch,\n",
    "                'net': net,\n",
    "                'y_out': y_out,\n",
    "                'n_smps': n_smps,\n",
    "                'n_sms' : n_sms,\n",
    "                'n_iter': n_iter,\n",
    "                \"num_cl\": num_cl,\n",
    "}\n",
    "\n",
    "if \"Robustness\" in properties:\n",
    "\n",
    "    if 'MLP' in net:\n",
    "      metrics = {\"AvgSensitivity\": quantus.AvgSensitivity(nr_samples= config['n_sms'],\n",
    "                                                      lower_bound=0.1,\n",
    "                                                      norm_numerator=quantus.fro_norm,\n",
    "                                                      norm_denominator=quantus.fro_norm,\n",
    "                                                      perturb_func=quantus.gaussian_noise,\n",
    "                                                      similarity_func= quantus.difference,\n",
    "                                                      disable_warnings= True,normalise=True)}\n",
    "    else:\n",
    "      metrics = dict()\n",
    "\n",
    "\n",
    "    metrics[\"LocalLipschitzEstimate\"] = quantus.LocalLipschitzEstimate(\n",
    "                                                          nr_samples = config['n_sms'],\n",
    "                                                          perturb_std =0.1,\n",
    "                                                          perturb_mean= 0,\n",
    "                                                          norm_numerator= quantus.distance_euclidean,\n",
    "                                                          norm_denominator= quantus.distance_euclidean,\n",
    "                                                          perturb_func = quantus.gaussian_noise,\n",
    "                                                          similarity_func = quantus.lipschitz_constant,normalise=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    params['min_norm'] = list(metrics.keys())\n",
    "    config['property'] = \"Robustness_0\"\n",
    "\n",
    "elif \"Faithfulness\"in properties:\n",
    "    metrics = {\n",
    "        \"FaithfulnessCorrelation\": quantus.FaithfulnessCorrelation(\n",
    "            nr_runs=n_smps,\n",
    "            subset_size=40,\n",
    "            perturb_baseline=\"uniform\",\n",
    "            perturb_func=quantus.baseline_replacement_by_indices,\n",
    "            similarity_func=quantus.correlation_pearson,\n",
    "            return_aggregate=False,\n",
    "            normalise=True, ),\n",
    "        \"ROAD\": quantus.ROAD(noise=0.01,\n",
    "                             normalise=True,\n",
    "                             perturb_baseline=\"uniform\",\n",
    "                             perturb_func=quantus.noisy_linear_imputation,\n",
    "                             percentages=np.linspace(1, 50, n_smps).tolist()), }\n",
    "    params['min_norm'] = [\"ROAD\"]\n",
    "    config['property'] = \"Faithfulness_0\"\n",
    "else:\n",
    "    metrics = {\n",
    "        \"Complexity:Complexity\": quantus.Complexity(\n",
    "            normalise=True,\n",
    "            disable_warnings=True),\n",
    "        \"Complexity:Sparseness\": quantus.Sparseness(\n",
    "            normalise=True,\n",
    "            disable_warnings=True),\n",
    "        \"Localisation:TopK\": quantus.TopKIntersection(\n",
    "            normalise=True,\n",
    "            disable_warnings=True,\n",
    "            k=(int(0.01 * int(lat.shape[0]) * int(lon.shape[0])))),\n",
    "        \"Localisation:RRA\": quantus.RelevanceRankAccuracy(\n",
    "            normalise=True,\n",
    "            disable_warnings=True),\n",
    "        \"Randomisation\": quantus.ModelParameterRandomisation(layer_order=\"bottom_up\",\n",
    "                                                             similarity_func=quantus.correlation_spearman,\n",
    "                                                             normalise=True),}\n",
    "    if 'MLP' in net:\n",
    "        metrics[\"RandomLogit\"] = quantus.RandomLogit(\n",
    "            normalise=True,\n",
    "            num_classes=num_cl,\n",
    "            similarity_func=quantus.correlation_spearman, )\n",
    "\n",
    "    params['min_norm'] = [\"Complexity:Complexity\", \"Randomisation\", \"RandomLogit\"]\n",
    "    config['property'] = \"Complexity_0\""
   ],
   "metadata": {
    "id": "lPIFRKPxxNV0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Set up reference dict\n",
    "reference = {}\n",
    "for i in range(len(ref)):\n",
    "  if type(ref[i]) is dict:\n",
    "    if 'Randomisation' in list(metrics.keys())[i]:\n",
    "       for j in range(len(list(ref[i].keys()))):\n",
    "        key = list(ref[i].keys())[j]\n",
    "        ref[i][key] = np.ones((len(ref[i][key]),))\n",
    "       reference[list(metrics.keys())[i]] = ref[i]\n",
    "    else:\n",
    "        reference[list(metrics.keys())[i]] = ref[i]\n",
    "  else:\n",
    "    reference[list(metrics.keys())[i]] = np.asarray(ref[i])"
   ],
   "metadata": {
    "id": "Aw4N4UOyPHQV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run experiment"
   ],
   "metadata": {
    "id": "Eb6-07dz1qmd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Intiate intermediate results save.\n",
    "csv_files = 'inter_results_%s_xai_%s_%s.csv' % (properties,len(xai_methods), config['net'])\n",
    "params['dirout'] = save_path\n",
    "params['csvfile'] = csv_files\n",
    "print('>>>>> Run %s analysis and baseline test <<<<<' % properties)\n",
    "# Run Quantus.\n",
    "results = run_quantus(arguments,explanations,metrics,xai_methods, **params)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UGDwWPc702u-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689186234520,
     "user_tz": -120,
     "elapsed": 16974,
     "user": {
      "displayName": "Philine Lou",
      "userId": "11745850249216413368"
     }
    },
    "outputId": "35d64c35-d88a-4e08-fc21-1938762e38b6"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>>>> Run Complexity_0 analysis and baseline test <<<<<\n",
      "Complexity:Complexity : DeepSHAP\n",
      "Complexity:Sparseness : DeepSHAP\n",
      "Localisation:TopK : DeepSHAP\n",
      "Localisation:RRA : DeepSHAP\n",
      "Randomisation : DeepSHAP\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate scores\n",
    "- calculate and save skill scores in a numpy '.npz'-file"
   ],
   "metadata": {
    "id": "0eMyanIM1trr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs = pd.DataFrame.from_dict(results)\n",
    "\n",
    "# Set aggregation params.\n",
    "params['num_xai'] = len(xai_methods)\n",
    "\n",
    "# Statistics: brier skill score\n",
    "bss_mean, bss_sem = bss_mean_var(metrics,xai_methods, results, reference, **params)\n",
    "\n",
    "bss2 = pd.DataFrame.from_dict(bss_sem)\n",
    "bss = pd.DataFrame.from_dict(bss_mean)\n",
    "\n",
    "# Save SEM BSS.\n",
    "np.savez(save_path + 'bss_%s_SEM_scores_xai_%s_%s.npz'% (properties,len(xai_methods), net), sem = bss2.values, xai = xai_methods[0][0], properties = bss2.columns.values)\n",
    "\n",
    "# Save mean BSS.\n",
    "np.savez(save_path + 'bss_%s_abs_agg_scores_xai_%s_%s.npz' % (properties,len(xai_methods), net), mean = bss.values, xai = xai_methods[0][0], properties = bss.columns.values)\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Og6pc6UO1Jh3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689186236610,
     "user_tz": -120,
     "elapsed": 2103,
     "user": {
      "displayName": "Philine Lou",
      "userId": "11745850249216413368"
     }
    },
    "outputId": "79b477a4-2ba4-4c17-b43d-3668a2222010"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Complexity:Complexity \n",
      "\n",
      "scores: [[8.79207698 8.684202   9.20592117 8.95304717 9.20413404 8.68367985\n",
      "  9.12495122 8.99593703 8.94811223 8.83899008 9.05229144 9.01394969\n",
      "  9.04962166 8.74869978 9.10583063 8.8485133  9.04652193 8.95927355\n",
      "  8.6940937  8.99092313 9.10368441 9.12926649 8.92240323 8.84576479\n",
      "  9.16139004 9.17886412 8.75139114 9.07302641 9.03731666 9.13541147\n",
      "  9.07468621 8.78691811 9.0169081  9.11549435 9.1857293  8.88237359\n",
      "  8.71953023 9.06770443 8.79576085 8.73677593 9.06847041 8.72058222\n",
      "  9.18817063 9.07696617 8.98938953 8.86273159 9.14942472 8.77978836\n",
      "  8.81477131 9.15427981]]\n",
      "ref: [[9.17664792 9.1501766  9.13662945 9.14530576 9.13735445 9.17285714\n",
      "  9.13719639 9.17425328 9.17570316 9.17406199 9.14095628 9.16999619\n",
      "  9.16516854 9.1740146  9.15737853 9.17382023 9.16753486 9.13975896\n",
      "  9.17525423 9.17680795 9.15287837 9.13772086 9.14063365 9.17143283\n",
      "  9.13831851 9.14523687 9.1509302  9.17577137 9.16371386 9.15155839\n",
      "  9.1710098  9.13389663 9.17261187 9.15373951 9.13557963 9.17207457\n",
      "  9.13804695 9.16949737 9.17388314 9.17432602 9.14153554 9.14006904\n",
      "  9.16429407 9.15603365 9.1715728  9.17523172 9.15708821 9.15594093\n",
      "  9.17317697 9.1579637 ]]\n",
      "Randomisation \n",
      "\n",
      "scores: [[0.02873431 0.00354075 0.04472846 0.00566769 0.02596137 0.02438521\n",
      "  0.0359747  0.09069462 0.00066845 0.06356395 0.04493119 0.0577567\n",
      "  0.01521678 0.01260688 0.1008596  0.16243599 0.00858319 0.01065406\n",
      "  0.02491326 0.05643495 0.11788561 0.02592803 0.05757009 0.00174181\n",
      "  0.04141689 0.04105084 0.04211943 0.08576766 0.01317057 0.06147679\n",
      "  0.04342832 0.00864141 0.02423534 0.08532748 0.01961462 0.05767638\n",
      "  0.03332639 0.04044328 0.03105531 0.01748307 0.02169063 0.04334281\n",
      "  0.00403449 0.11462309 0.08291967 0.03115654 0.06454352 0.01518158\n",
      "  0.00540902 0.04328303 0.0635333  0.12425387 0.04316615 0.09092571\n",
      "  0.03114686 0.04928992 0.07387122 0.05987419 0.04105803 0.1693905\n",
      "  0.00074234 0.07089165 0.02003451 0.16211569 0.06528638 0.066417\n",
      "  0.03336967 0.00800863 0.00161265 0.069872   0.08534248 0.02887558\n",
      "  0.08736347 0.02103237 0.02947926 0.06812266 0.03791084 0.04251955\n",
      "  0.01333935 0.06076405 0.05540074 0.05697726 0.03800981 0.0449788\n",
      "  0.0149643  0.11207446 0.12942768 0.03211991 0.00757493 0.04857898\n",
      "  0.01206541 0.00805221 0.04169134 0.05967938 0.08182854 0.07416556\n",
      "  0.06513892 0.0124848  0.00379067 0.10296255 0.06783589 0.06791653\n",
      "  0.06365652 0.03751141 0.00797702 0.05908221 0.05272443 0.06234622\n",
      "  0.03614982 0.04082726 0.05925744 0.09217681 0.00306677 0.00864794\n",
      "  0.04587574 0.12321949 0.03072731 0.03554639 0.00572131 0.0447877\n",
      "  0.11481041 0.06013071 0.01549985 0.0143316  0.07458495 0.04670697\n",
      "  0.01646434 0.09726169 0.01258109 0.04644695 0.0132225  0.05362495\n",
      "  0.03763542 0.06292044 0.00268143 0.05225548 0.05793365 0.05243652\n",
      "  0.00508945 0.01896542 0.05259526 0.03570908 0.09246103 0.08353524\n",
      "  0.04411613 0.01385143 0.06658375 0.08235004 0.04964132 0.08828559]]\n",
      "ref: [[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ]
  }
 ]
}